{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vmp_nz4kIH1v"
      },
      "outputs": [],
      "source": [
        "# Install the necessary library\n",
        "!pip install --quiet google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Set your Gemini API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "IOFDnNK7ImcF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose your model\n",
        "MODEL = \"gemini-2.5-flash\"  # Ensure this model is available in your region\n",
        "DATA_FILE = \"cloudcost_records.json\"\n",
        "\n",
        "# Sample metrics\n",
        "sample_metrics = [\n",
        "    {\"service\": \"VM-1\", \"cpu_usage\": 75, \"memory_usage\": 60, \"daily_cost\": 12.5},\n",
        "    {\"service\": \"VM-2\", \"cpu_usage\": 10, \"memory_usage\": 20, \"daily_cost\": 8.0},\n",
        "    {\"service\": \"Storage-1\", \"usage_gb\": 1200, \"daily_cost\": 5.0}\n",
        "]\n"
      ],
      "metadata": {
        "id": "d9LvaomYISr3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to call Gemini\n",
        "def ask_gemini(prompt: str):\n",
        "    model = genai.GenerativeModel(MODEL)\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "2XTEkWlRI5b_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save records\n",
        "def save_record(record: dict):\n",
        "    data = []\n",
        "    if os.path.exists(DATA_FILE):\n",
        "        with open(DATA_FILE, \"r\") as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "            except:\n",
        "                data = []\n",
        "    data.append(record)\n",
        "    with open(DATA_FILE, \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "pmMK6hX-J6Ia"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent orchestration function\n",
        "def agent_step(metrics):\n",
        "    system_msg = \"\"\"\n",
        "You are CloudCostAI, an intelligent SRE assistant.\n",
        "Analyze the following metrics, detect anomalies, forecast future cost, and recommend optimizations.\n",
        "Provide JSON with keys: baseline, forecast, anomalies, recommendations.\n",
        "\"\"\"\n",
        "    prompt = f\"{system_msg}\\nMetrics:\\n{json.dumps(metrics)}\"\n",
        "    gemini_reply = ask_gemini(prompt)\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(gemini_reply)\n",
        "    except:\n",
        "        parsed = {\"raw_text\": gemini_reply}\n",
        "\n",
        "    save_record({\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"metrics\": metrics,\n",
        "        \"agent_output\": parsed\n",
        "    })\n",
        "\n",
        "    return parsed\n",
        "\n"
      ],
      "metadata": {
        "id": "TWXUD_HiJ9mW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "sample_metrics = {\"cost\": [100, 120, 130, 160, 155, 190]}  # example input\n",
        "output = agent_step(sample_metrics)\n",
        "print(json.dumps(output, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "eDs1mFrdKElh",
        "outputId": "6f364811-29e7-48d0-de55-5d7f5860581d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"raw_text\": \"```json\\n{\\n  \\\"baseline\\\": {\\n    \\\"observation\\\": \\\"The cost trend is consistently upward, starting from 100 and reaching 190 over six periods, indicating a clear pattern of increasing expenditure. The average increase per period is approximately 18.\\\"\\n  },\\n  \\\"forecast\\\": {\\n    \\\"next_period_cost\\\": 210,\\n    \\\"methodology\\\": \\\"Based on a blend of the overall average increase and recent trends (specifically, the average of the last three deltas: +30, -5, +35, resulting in an average increase of +20), the next period's cost is projected to continue its upward trajectory.\\\"\\n  },\\n  \\\"anomalies\\\": [\\n    {\\n      \\\"period_start_value\\\": 130,\\n      \\\"period_end_value\\\": 160,\\n      \\\"change\\\": \\\"+30\\\",\\n      \\\"type\\\": \\\"Accelerated Growth\\\",\\n      \\\"description\\\": \\\"A significant jump of 30 units from 130 to 160, representing an acceleration in cost growth compared to earlier periods' increases (+20, +10).\\\"\\n    },\\n    {\\n      \\\"period_start_value\\\": 160,\\n      \\\"period_end_value\\\": 155,\\n      \\\"change\\\": \\\"-5\\\",\\n      \\\"type\\\": \\\"Unexpected Dip\\\",\\n      \\\"description\\\": \\\"A brief and unusual decrease of 5 units from 160 to 155. This breaks the continuous upward trend and warrants investigation to understand if it was a temporary reduction in usage, an optimization, or a reporting anomaly.\\\"\\n    },\\n    {\\n      \\\"period_start_value\\\": 155,\\n      \\\"period_end_value\\\": 190,\\n      \\\"change\\\": \\\"+35\\\",\\n      \\\"type\\\": \\\"Highest Growth Spike\\\",\\n      \\\"description\\\": \\\"The largest single increase observed (+35) following the temporary dip, indicating a strong and rapid surge in costs in the most recent period.\\\"\\n    }\\n  ],\\n  \\\"recommendations\\\": [\\n    {\\n      \\\"category\\\": \\\"Root Cause Analysis\\\",\\n      \\\"items\\\": [\\n        \\\"**Investigate Cost Spikes:** Conduct a deep dive into the periods exhibiting accelerated growth (from 130 to 160, and 155 to 190). Identify specific services, resources, or usage patterns that contributed to these significant increases. Look for new deployments, scaling events, or increased traffic.\\\",\\n        \\\"**Analyze Temporary Dip:** Understand the reason for the brief cost reduction (160 to 155). If it was due to an optimization, document it and explore if it can be scaled or replicated. If it was reduced usage, monitor for consistent patterns or anomalies in demand.\\\"\\n      ]\\n    },\\n    {\\n      \\\"category\\\": \\\"Resource Optimization\\\",\\n      \\\"items\\\": [\\n        \\\"**Rightsizing:** Review compute (VMs, containers), database, and storage resources to ensure they are appropriately sized for actual demand. Eliminate over-provisioning (e.g., oversized instances, underutilized CPUs/RAM).\\\",\\n        \\\"**Identify & Terminate Idle Resources:** Use cloud provider tools or third-party solutions to detect and delete unused or underutilized resources (e.g., old snapshots, unattached volumes, idle development environments, forgotten services).\\\",\\n        \\\"**Storage Optimization:** Implement lifecycle policies for object storage, move infrequently accessed data to colder storage tiers, and ensure obsolete backups/snapshots are regularly deleted.\\\"\\n      ]\\n    },\\n    {\\n      \\\"category\\\": \\\"Cost Commitment & Governance\\\",\\n      \\\"items\\\": [\\n        \\\"**Leverage Reserved Instances/Savings Plans:** For stable, long-running workloads identified during the root cause analysis, evaluate the use of Reserved Instances (RIs) or Savings Plans to achieve significant discounts.\\\",\\n        \\\"**Implement FinOps Practices:** Foster a culture of cost awareness among engineering teams. Ensure consistent tagging for better cost allocation and implement chargeback mechanisms where appropriate to drive accountability.\\\",\\n        \\\"**Automated Monitoring & Alerting:** Set up proactive cost alerts for unexpected spikes, deviations from forecasts, or changes in resource utilization to enable rapid response and prevent uncontrolled spending.\\\"\\n      ]\\n    },\\n    {\\n      \\\"category\\\": \\\"Network & Data Transfer\\\",\\n      \\\"items\\\": [\\n        \\\"**Review Network Egress Costs:** Analyze data transfer out of regions or across different cloud providers, as these can be significant cost drivers. Optimize data transfer paths and explore content delivery network (CDN) options.\\\"\\n      ]\\n    }\\n  ]\\n}\\n```\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3611696044.py:17: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat(),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNgdz4pRKc9d"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
